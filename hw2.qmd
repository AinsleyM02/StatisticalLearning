---
title: "Homework #2: Resampling" 
author: "**Ainsley McLaughlin**"
format: ds6030hw-html
---

```{r config, include=FALSE}
# Set global configurations and settings here
knitr::opts_chunk$set()                 # set global chunk options
ggplot2::theme_set(ggplot2::theme_bw()) # set ggplot2 theme
```


# Required R packages and Directories {.unnumbered .unlisted}

```{r packages, message=FALSE, warning=FALSE}
data_dir = 'https://mdporter.github.io/teaching/data/' # data directory
library(tidymodels)# for optional tidymodels solutions
library(tidyverse) # functions for data manipulation  
```


# Problem 1: Bootstrapping 

Bootstrap resampling can be used to quantify the uncertainty in a fitted curve. 

## a. Data Generating Process

Create a set of functions to generate data from the following distributions:
\begin{align*}
X &\sim \mathcal{U}(0, 2) \qquad \text{Uniform between $0$ and $2$}\\
Y &= 1 + 2x + 5\sin(5x) + \epsilon \\
\epsilon &\sim \mathcal{N}(0,\, \sigma=2.5)
\end{align*}

::: {.callout-note title="Solution"}

```{r}
X_fun<-function(n){
  runif(n, min = 0, max = 2) #from a uniform with n observations
}

f <- function(x) {
  1 + 2*x + 5*sin(5*x)     # true mean function
}

Y_fun <- function(x){     # generate Y|X from N{f(x),sd}
  n = length(x)
  f(x) + rnorm(n, mean=0, sd=sqrt(2.5))
}
```

:::

## b. Simulate data

Simulate $n=100$ realizations from these distributions. Produce a scatterplot and draw the true regression line $f(x) = E[Y \mid X=x]$. Use `set.seed(211)` prior to generating the data.

::: {.callout-note title="Solution"}

```{r}
library(tidyverse)
#set seed for replicability
set.seed(211)
#sim data w 100 obsv
x = X_fun(100)
y = Y_fun(x)
#put into a df (tibble)
data_sim<-tibble(X=x,Y=y)
#View(data_sim)


#plot
library(ggplot2)
ggplot(data_sim, aes(x,y))+
  geom_point()+
  geom_function(fun=f, color="orange")

```

:::


## c. 5th degree polynomial fit

Fit a 5th degree polynomial. Produce a scatterplot and draw the *estimated* regression curve.

::: {.callout-note title="Solution"}

```{r}
#fit the model
fifth_poly<-lm(y ~ poly(x, degree = 5), data = data_sim)

# Create predictions for plotting, add to the df that exists
data_sim$poly5_pred <- predict(fifth_poly, newdata = data_sim)

#plot
ggplot(data_sim, aes(x,y))+
  geom_point()+
  geom_function(fun=f, aes(color = "True_regression"))+
  geom_line(aes(y = poly5_pred, color="Fifth_deg"))+
  labs(title = "Scatterplot with Estimated Regression Lines",
       x = "X",
       y = "Y")+
  scale_color_manual(values=c('Fifth_deg'='blue','True_regression'='orange'))
```

:::


## d. Bootstrap sampling

Make 200 bootstrap samples. For each bootstrap sample, fit a 5th degree polynomial and make predictions at `eval_pts = seq(0, 2, length=100)`

- Set the seed (use `set.seed(212)`) so your results are reproducible.
- Produce a scatterplot with the original data and add the 200 bootstrap curves

::: {.callout-note title="Solution"}


```{r}

# july 16th in princes class we did this
# Set the seed for reproducibility
set.seed(212)

# Number of bootstrap samples
n_boot = 200

# Define evaluation points for predictions
eval_pts = seq(0, 2, length = 100)

# Initialize an empty tibble to store predictions
preds <- list()

# Loop over the number of bootstrap samples
for (i in 1:n_boot) { # basically from 1 to 200
  
  # Sample from the original training data with replacement
  ind = sample(1:nrow(data_sim), replace = TRUE) # Sample row indices
  data_boot = data_sim[ind, ] # Create bootstrap sample
  
  # Fit 5th-degree polynomial model
  m_boot = lm(y ~ poly(x, degree = 5), data = data_boot) # Fit polynomial model
  
  # Predict values at the evaluation points
  poly5_pred = predict(m_boot, newdata = data.frame(x=eval_pts))
  
  # Store the predictions in the preds tibble
  preds[[i]]<-data.frame(x=eval_pts, y=poly5_pred, iteration=i)
  
  preds_data <- bind_rows(preds)
}

# Visualize: Scatterplot with original data and 200 bootstrap curves
ggplot(data_sim, aes(x = x, y = y)) +
  geom_point(color = "blue") +  # Scatterplot of original data
  geom_line(data = preds_data, aes(x = x, y = y, group = iteration), 
            color = "red", alpha = 0.4) +  # 200 bootstrap prediction curves
  labs(title = "Bootstrap Predictions with 200 bootstrap curves",
       x = "X", y = "Y")
```
```{r}
# chat's edits which still do not work: 
# Set the seed for reproducibility
set.seed(212)

# Number of bootstrap samples
n_boot = 200

# Define evaluation points for predictions
eval_pts = data.frame(x = seq(0, 2, length = 100)) # Create a data frame for eval_pts

# Initialize an empty list to store predictions
preds <- vector("list", n_boot)

# Loop over the number of bootstrap samples
for (i in 1:n_boot) {
  
  # Sample from the original training data with replacement
  ind = sample(1:nrow(data_sim), replace = TRUE) # Sample row indices
  data_boot = data_sim[ind, ] # Create bootstrap sample
  
  # Fit 5th-degree polynomial model
  m_boot = lm(y ~ poly(x, degree = 5), data = data_boot) # Fit polynomial model
  
  # Predict values at the evaluation points
  poly5_pred = predict(m_boot, newdata = eval_pts)
  
  # Store the predictions in the preds list, assigning iteration as i
  preds[[i]] <- data.frame(x = eval_pts$x, y = poly5_pred, iteration = i)
}

# Combine all predictions into a single data frame
preds_data <- bind_rows(preds)

# Visualize: Scatterplot with original data and 200 bootstrap curves
ggplot(data_sim, aes(x = x, y = y)) +
  geom_point(color = "blue") +  # Scatterplot of original data
  geom_line(data = preds_data, aes(x = x, y = y, group = iteration), 
            color = "red", alpha = 0.2) +  # 200 bootstrap prediction curves
  labs(title = "Bootstrap Predictions with 200 bootstrap curves",
       x = "X", y = "Y")

```
```{r}
# try with the function replicated instead:
# Set the seed for reproducibility
set.seed(212)

# Number of bootstrap samples
n_boot = 200

# Define evaluation points for predictions
eval_pts = seq(0, 2, length = 100) 
# function for the prediction points and sampling with replacement
pred_samp_fun<-function(train_data, evals){
  # sample with replacement at that index
  boot_samp = train_data[sample(1:nrow(train_data), replace = TRUE),]
  # Fit polynomial model
  poly5_boot_fit = lm(y ~ poly(x, degree = 5), data = boot_samp) 
  #predict
  predict(poly5_boot_fit, newdata = data.frame(x=evals))
  
}
# call this function 200 times:
boot_preds<-replicate(200, pred_samp_fun(data_sim, eval_pts))
boot_pred_df<-data.frame(boot_preds)

# plot
ggplot(data_sim, aes(x = x, y = y)) +
  geom_point(color = "blue") +  # Scatterplot of original data
  geom_line(data = boot_pred_df, aes(x = x, y = y), 
            color = "green", alpha = 0.2) +  # 200 bootstrap prediction curves
  labs(title = "Bootstrap Predictions with 200 bootstrap curves",
       x = "X", y = "Y")
```

```{r}
# Set the seed for reproducibility
set.seed(212)

# Number of bootstrap samples
n_boot <- 200

# Define evaluation points for predictions
eval_pts <- seq(0, 2, length = 100)

# Function for the prediction points and sampling with replacement
pred_samp_fun <- function(train_data, evals) {
  # sample with replacement at that index
  boot_samp <- train_data[sample(1:nrow(train_data), replace = TRUE),]
  # Fit polynomial model
  poly5_boot_fit <- lm(y ~ poly(x, degree = 5), data = boot_samp) 
  # Predict
  predict(poly5_boot_fit, newdata = data.frame(x = evals))
}

# Call this function 200 times and structure the output
boot_preds <- replicate(n_boot, pred_samp_fun(data_sim, eval_pts))

# Reshape predictions into a data frame with 'x' and 'y' columns
boot_pred_df <- data.frame(x = eval_pts, boot_preds)
boot_pred_long <- boot_pred_df %>%
  pivot_longer(cols = starts_with("X"), names_to = "sample", values_to = "y")

# Plot
ggplot(data_sim, aes(x = x, y = y)) +
  geom_point(color = "blue") +  # Scatterplot of original data
  geom_line(data = boot_pred_long, aes(x = x, y = y, group = sample), 
            color = "green", alpha = 0.2) +  # 200 bootstrap prediction curves
  labs(title = "Bootstrap Predictions with 200 bootstrap curves",
       x = "X", y = "Y")
```
:::
    
## e. Confidence Intervals

Calculate the pointwise 95% confidence intervals from the bootstrap samples. That is, for each $x \in {\rm eval\_pts}$, calculate the upper and lower limits such that only 5% of the curves fall outside the interval at $x$. 

- Remake the plot from part *c*, but add the upper and lower boundaries from the 95% confidence intervals. 

::: {.callout-note title="Solution"}

```{r}

```

:::

# Problem 2: V-Fold cross-validation with $k$ nearest neighbors

Run 10-fold cross-validation on the data generated in part 1b to select the optimal $k$ in a k-nearest neighbor (kNN) model. Then evaluate how well cross-validation performed by evaluating the performance on a large test set. The steps below will guide you.


## a. Implement 10-fold cross-validation

Use $10$-fold cross-validation to find the value of $k$ (i.e., neighborhood size) that provides the smallest cross-validated MSE using a kNN model. 

- Search over $k=3,4,\ldots, 40$.
- Use `set.seed(221)` prior to generating the folds to ensure the results are replicable. 
- Show the following:
    - the optimal $k$ (as determined by cross-validation)
    - the corresponding estimated MSE
    - produce a plot with $k$ on the x-axis and the estimated MSE on the y-axis (optional: add 1-standard error bars). 
- Notation: The $k$ is the tuning paramter for the kNN model. The $v=10$ is the number of folds in V-fold cross-validation. Don't get yourself confused.

::: {.callout-note title="Solution"}

Add solution here

:::


## b. Find the optimal *edf*

The $k$ (number of neighbors) in a kNN model determines the effective degrees of freedom *edf*. What is the optimal *edf*? Be sure to use the correct sample size when making this calculation. Produce a plot similar to that from part *a*, but use *edf* (effective degrees of freedom) on the x-axis. 

::: {.callout-note title="Solution"}

Add solution here

:::

## c. Choose $k$

After running cross-validation, a final model fit from *all* of the training data needs to be produced to make predictions. What value of $k$ would you choose? Why? 

::: {.callout-note title="Solution"}

Add solution here

:::

## d. Evaluate actual performance

Now we will see how well cross-validation performed. Simulate a test data set of $50000$ observations from the same distributions. Use `set.seed(223)` prior to generating the test data. 

- Fit a set of kNN models, using the full training data, and calculate the mean squared error (MSE) on the test data for each model. Use the same $k$ values in *a*. 
- Report the optimal $k$, the corresponding *edf*, and MSE based on the test set.

::: {.callout-note title="Solution"}

Add solution here

:::

## e. Performance plots

Plot both the cross-validation estimated and (true) error calculated from the test data on the same plot. See Figure 5.6 in ISL (pg 182) as a guide. 

- Produce two plots: one with $k$ on the x-axis and one with *edf* on the x-axis.
- Each plot should have two lines: one from part *a* and one from part *d* 
    
::: {.callout-note title="Solution"}

Add solution here

:::
    
## f. Did cross-validation work as intended?

Based on the plots from *e*, does it appear that cross-validation worked as intended? How sensitive is the choice of $k$ on the resulting test MSE?      

::: {.callout-note title="Solution"}

Add solution here

:::




